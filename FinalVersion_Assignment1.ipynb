{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ea63a3",
   "metadata": {},
   "source": [
    "## Assignment 1 \n",
    "### Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90404509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import gutenberg\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c655e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Section Contributed</th>\n",
       "      <th>Section Edited</th>\n",
       "      <th>Other Contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poon Dustin</td>\n",
       "      <td>301389544</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Line 1-15</td>\n",
       "      <td>Supplied with :&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wong Esther</td>\n",
       "      <td>301328854</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Line 8-10</td>\n",
       "      <td>Suppied with :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horstead Matt</td>\n",
       "      <td>301350353</td>\n",
       "      <td>ALL</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Supplied with :D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Student ID Section Contributed Section Edited  \\\n",
       "0    Poon Dustin  301389544                 ALL      Line 1-15   \n",
       "1    Wong Esther  301328854                 ALL      Line 8-10   \n",
       "2  Horstead Matt  301350353                 ALL            N/A   \n",
       "\n",
       "  Other Contribution  \n",
       "0   Supplied with :>  \n",
       "1    Suppied with :)  \n",
       "2   Supplied with :D  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Name': ['Poon Dustin', 'Wong Esther', 'Horstead Matt'],\n",
    "        'Student ID': ['301389544', \"301328854\", '301350353'],\n",
    "        'Section Contributed': ['ALL','ALL','ALL'],\n",
    "        'Section Edited': ['Line 1-15','Line 8-10','N/A'],\n",
    "        'Other Contribution': ['Supplied with :>','Suppied with :)','Supplied with :D']}\n",
    "why = pd.DataFrame(data, columns=['Name', 'Student ID', 'Section Contributed', 'Section Edited', 'Other Contribution'])\n",
    "why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6412bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length for blog corpus: 8353\n",
      "The length for academic corpus: 7167\n",
      "The length for fiction corpus: 46660\n"
     ]
    }
   ],
   "source": [
    "corpus_root = \"./assignmentfiles/\"\n",
    "mycorpus = PlaintextCorpusReader(corpus_root, \".*\")\n",
    "\n",
    "text1 = mycorpus.words(\"BlogCorpus.txt\")\n",
    "text2 = mycorpus.words(\"ResearchArticle.txt\")\n",
    "text3 = mycorpus.words(\"AtTheMountainsOfMadness.txt\")\n",
    "\n",
    "#data = [text1, text2, text3]\n",
    "#for text in data:\n",
    "    #print(\"The length for text\", text ,len(text))\n",
    "\n",
    "tkBlogs=len(text1) #tokens\n",
    "tkAcadm=len(text2)\n",
    "tkFic=len(text3)\n",
    "\n",
    "print(\"The length for blog corpus:\",tkBlogs)\n",
    "print(\"The length for academic corpus:\",tkAcadm)\n",
    "print(\"The length for fiction corpus:\",tkFic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e885aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical diveristy for Blog Collection: 0.196\n",
      "Lexical diveristy for Academic Collection: 0.19\n",
      "Lexical diveristy for Fiction Collection: 0.14\n"
     ]
    }
   ],
   "source": [
    "tyBlogs=len(set(text1)) #types\n",
    "tyAcadm=len(set(text2)) \n",
    "tyFic=len(set(text3))\n",
    "\n",
    "lexDiv1= tyBlogs/tkBlogs\n",
    "lexDiv2= tyAcadm/tkAcadm\n",
    "lexDiv3= tyFic/tkFic\n",
    "\n",
    "print(\"Lexical diveristy for Blog Collection:\",round(lexDiv1,3))\n",
    "print(\"Lexical diveristy for Academic Collection:\",round(lexDiv2,3))\n",
    "print(\"Lexical diveristy for Fiction Collection:\",round(lexDiv3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d431a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Longest Sentence in Text 1 , with [166] words: \n",
      " This is a vision described in Revelation 7 : 9 - 10 : â  After this I looked , and behold , a great multitude that no one could number , from every nation , from all tribes and peoples and languages , standing before the throne and before the Lamb , clothed in white robes , with palm branches in their hands , and crying out with a loud voice , â  Salvation belongs to our God who sits on the throne , and to the Lamb ! â  â  â  Itâ  s through the gospel that we can see how God calls us to an amazing identity , one that is rooted in the gospelâ  a gospel that saves people of all tribes , tongues , and nations , a gospel that celebrates each culture in the ways it can reflect him , a gospel that redeems the parts of cultures that are broken by sin .\n"
     ]
    }
   ],
   "source": [
    " #i combined q3 and 6 together\n",
    "file1_sentences= gutenberg.sents(\"BlogCorpus.txt\") #pathfile coverted to sentences\n",
    "longest_len = max(len(s) for s in file1_sentences) #find the longest entence in pathfile\n",
    "longest_sent_count=[len(s) for s in file1_sentences if len(s) == longest_len] #when sentence length is logest output each word \n",
    "#[s for s in file1_sentences if len(s) == longest_len]  #this code turns the longest sentence in to a list \n",
    "#question 3 is here\n",
    "\n",
    "c=[s for s in file1_sentences if len(s) == longest_len] #turn the function into variable #this is question 6\n",
    "for i in c:  #join each word in the c list\n",
    "    longest_sent=( \" \".join(i))\n",
    "\n",
    "print(\"This is the Longest Sentence in Text 1 , with\", longest_sent_count,\"words: \\n\", longest_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44c2124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Longest Sentence in Text 2 , with [191] words: \n",
      " Hierarchical regression results of the mediation effect of reward expectancy between abusive supervision and OCBO and OCBIa OCBO ( T2 ) OCBI ( T2 ) M1 M2 M3 M1 M2 M3 Step 1 Abusive supervision \u0001 0 . 28 ** \u0001 0 . 17 * \u0001 0 . 13 \u0001 0 . 07 0 . 01 0 . 02 Change in R2 0 . 08 ** 0 . 01 Step 2 Reward expectancy ( T2 ) 0 . 38 ** 0 . 26 ** 0 . 28 ** 0 . 24 ** Change in R2 0 . 13 ** 0 . 07 ** Step 3 Organizational identification ( T2 ) 0 . 36 ** 0 . 13 Change in R2 0 . 11 ** 0 . 01 Notes : a N = 142 ( list wise ); * p < 0 . 05 ; ** p < 0 . 01 Citizenship behavior 509 Supplementary analyses Supplementary analyses were conducted to : \u0004 examine the moderating role of prevention focus ; and \u0004 rule out the possibility that organizational identification may fully account the mediating effect we observed regarding reward expectancy .\n"
     ]
    }
   ],
   "source": [
    "file2_sentences= gutenberg.sents(\"ResearchArticle.txt\") #pathfile coverted to sentences\n",
    "longest_len2 = max(len(s) for s in file2_sentences) #find the longest entence in pathfile\n",
    "longest_sent_count2=[len(s) for s in file2_sentences if len(s) == longest_len2] #when sentence length is logest output each word \n",
    "\n",
    "\n",
    "c=[s for s in file2_sentences if len(s) == longest_len2] #turn the function into variable\n",
    "for i in c:  #join each word in the c list\n",
    "    longest_sent2=( \" \".join(i))\n",
    "\n",
    "print(\"This is the Longest Sentence in Text 2 , with\", longest_sent_count2,\"words: \\n\", longest_sent2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ff11da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Longest Sentence in Text 3 , with [152] words: \n",
      " As all know , our report included a tale of a hard ascent ; a confirmation of Lakeâ  s opinion that the great peaks are of Archaean slate and other very primal crumpled strata unchanged since at least middle Comanchian times ; a conventional comment on the regularity of the clinging cube and rampart formations ; a decision that the cave - mouths indicate dissolved calcareous veins ; a conjecture that certain slopes and passes would permit of the scaling and crossing of the entire range by seasoned mountaineers ; and a remark that the mysterious other side holds a lofty and immense super - plateau as ancient and unchanging as the mountains themselvesâ  20 , 000 feet in elevation , with grotesque rock formations protruding through a thin glacial layer and with low gradual foothills between the general plateau surface and the sheer precipices of the highest peaks .\n"
     ]
    }
   ],
   "source": [
    "file3_sentences= gutenberg.sents(\"AtTheMountainsOfMadness.txt\") #pathfile coverted to sentences\n",
    "longest_len3 = max(len(s) for s in file3_sentences) #find the longest entence in pathfile\n",
    "longest_sent_count3=[len(s) for s in file3_sentences if len(s) == longest_len3] #when sentence length is logest output each word \n",
    "\n",
    "\n",
    "c=[s for s in file3_sentences if len(s) == longest_len3] #turn the function into variable\n",
    "for i in c:  #join each word in the c list\n",
    "    longest_sent3=( \" \".join(i))\n",
    "\n",
    "print(\"This is the Longest Sentence in Text 3 , with\", longest_sent_count3,\"words: \\n\", longest_sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb9cda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":// p2c; https ://; Students https; Donate Media; birch tree; surg\n",
      "Passing; Medical misconcept; Finding support; disconnected Medical;\n",
      "secret Overwhelmed; scoliosis secret; PAGE Misunderstanding;\n",
      "concussion Keeping; medical journey; PAGE Excluded; two cultures;\n",
      "feeling well; take care; odd behaviour; psych ward\n"
     ]
    }
   ],
   "source": [
    "nltk.Text(text1).collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63da3788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abusive supervision; reward expectancy; promotion focus; prevention\n",
      "focus; citizenship behavior; task performance; organizational\n",
      "identification; indirect effect; per cent; Abusive supervision;\n",
      "organizational citizenship; alpha reliability; four items; civic\n",
      "virtue; moderated mediation; negative relationship; Citizenship\n",
      "behavior; high promotion; distributive justice; Promotion focus\n"
     ]
    }
   ],
   "source": [
    "nltk.Text(text2).collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf2e3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Ones; million years; years ago; McMurdo Sound; poor Lake; musical\n",
      "piping; 000 feet; greenish soapstones; dead city; could see; fifty\n",
      "million; miles away; ground level; electric torches; wide range; Queen\n",
      "Mary; aërial survey; good deal; feet high; outside world\n"
     ]
    }
   ],
   "source": [
    "nltk.Text(text3).collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5321069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 163),\n",
       " ('a', 114),\n",
       " ('as', 34),\n",
       " ('at', 33),\n",
       " ('articles', 18),\n",
       " ('all', 16),\n",
       " ('an', 16),\n",
       " ('about', 15),\n",
       " ('are', 12),\n",
       " ('after', 11)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords = nltk.corpus.stopwords.words('english')\n",
    "#vowels= \"a\",\"e\",\"i\",\"o\",\"u\"\n",
    "#for loop can be used\n",
    "#panda can be used\n",
    "fd1=nltk.FreqDist(w.lower() for w in text1 if w.isalpha() and w.startswith(\"a\"))\n",
    "fd1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e66296da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', 11),\n",
       " ('exiled', 7),\n",
       " ('end', 6),\n",
       " ('each', 6),\n",
       " ('else', 5),\n",
       " ('early', 5),\n",
       " ('every', 4),\n",
       " ('enough', 4),\n",
       " ('ever', 4),\n",
       " ('everything', 3)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd2=nltk.FreqDist(w.lower() for w in text1 if w.isalpha() and w.startswith(\"e\"))\n",
    "fd2.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f66ccd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 109),\n",
       " ('it', 60),\n",
       " ('is', 26),\n",
       " ('into', 17),\n",
       " ('identity', 10),\n",
       " ('if', 6),\n",
       " ('immigrant', 5),\n",
       " ('inside', 3),\n",
       " ('instead', 3),\n",
       " ('i', 3)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd3=nltk.FreqDist(w.lower() for w in text1 if w.isalpha() and w.startswith(\"i\"))\n",
    "fd3.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40867e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 141),\n",
       " ('on', 58),\n",
       " ('our', 25),\n",
       " ('out', 24),\n",
       " ('or', 19),\n",
       " ('one', 12),\n",
       " ('often', 10),\n",
       " ('off', 8),\n",
       " ('over', 6),\n",
       " ('only', 6)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd4=nltk.FreqDist(w.lower() for w in text1 if w.isalpha() and w.startswith(\"o\"))\n",
    "fd4.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04413226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('us', 22),\n",
       " ('up', 18),\n",
       " ('under', 5),\n",
       " ('until', 4),\n",
       " ('ushered', 4),\n",
       " ('understand', 3),\n",
       " ('use', 3),\n",
       " ('used', 2),\n",
       " ('unable', 2),\n",
       " ('understanding', 2)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd5=nltk.FreqDist(w.lower() for w in text1 if w.isalpha() and w.startswith(\"u\"))\n",
    "fd5.most_common(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
